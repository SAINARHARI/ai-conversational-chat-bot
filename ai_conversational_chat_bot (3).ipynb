{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **NLP Model Deployment Using Transformers**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Project Overview:\n",
        "This project focuses on building and deploying an NLP model using deep learning techniques and transformer-based architectures. The model was trained to process incoming messages and generate responses. Additionally, it integrates with platforms like Twilio for handling incoming and outgoing messages. The entire pipeline was developed, tested locally, and deployed to the cloud for public interaction.\n",
        "\n",
        "# What We Did?\n",
        "\n",
        "Model Development:\n",
        "\n",
        "Built an NLP model using Hugging Face Transformers.\n",
        "\n",
        "\n",
        "The model was trained for specific NLP tasks, such as text classification\n",
        "**response** generation, or sentiment analysis.\n",
        "Fine-tuned pre-trained transformer models (e.g., BERT, GPT) on a custom dataset.\n",
        "Integration with Twilio:\n",
        "\n",
        "Configured Twilio to handle incoming messages using a webhook.\n",
        "Developed a pipeline to send processed responses from the model back to the sender.\n",
        "Debugged network issues related to Twilio message delivery (e.g., potential network blocking, testing with ngrok).\n",
        "Local Testing:\n",
        "\n",
        "Successfully ran the application locally using Python and Flask/Gradio.\n",
        "Tested message processing through local APIs and ensured the model returned appropriate responses.\n",
        "Deployment:\n",
        "\n",
        "Deployed the application to Hugging Face Spaces, leveraging free cloud hosting for NLP models.\n",
        "Integrated Gradio to create a user-friendly web interface for public interaction with the model.\n",
        "\n",
        "# Challenges Faced:\n",
        "\n",
        "Debugging Twilio webhook-related issues and identifying network-related blocks.\n",
        "Handling deployment challenges, including ensuring compatibility of the model with cloud services.\n",
        "Testing message flow between Twilio and the deployed app.\n",
        "Technologies Used:\n",
        "\n",
        "Hugging Face Transformers for NLP modeling.\n",
        "Gradio for creating the interactive interface.\n",
        "Twilio API for handling SMS communication.\n",
        "Ngrok for local testing with public URLs.\n",
        "Hugging Face Spaces for cloud deployment.\n",
        "How It Works\n",
        "Input: Incoming messages are received from Twilio or directly entered via the Gradio interface.\n",
        "Processing: The message is passed to the deployed NLP model for processing (e.g., generating a response).\n",
        "Output: The response is either displayed in the web interface or sent back as an SMS through Twilio.\n"
      ],
      "metadata": {
        "id": "Uv4LwJgtXwVj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BItnj8bKVvhT",
        "outputId": "ab70e2e7-d59a-40aa-f07b-7f7bcc25c1d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON file created!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Define your JSON data\n",
        "chatbot_data = [\n",
        "  {\n",
        "    \"intent\": \"appointment_booking\",\n",
        "    \"patterns\": [\n",
        "      \"Book an appointment for {date}\",\n",
        "      \"Schedule an appointment on {date}\",\n",
        "      \"I want to book an appointment for {date}\",\n",
        "      \"Can I book an appointment for {date}?\",\n",
        "      \"Please schedule my appointment on {date}\",\n",
        "      \"Make an appointment for me on {date}\",\n",
        "      \"Reserve an appointment on {date}\",\n",
        "      \"I need an appointment for {date}\",\n",
        "      \"Set up an appointment for {date}\",\n",
        "      \"Schedule a meeting on {date}\"\n",
        "    ],\n",
        "    \"responses\": [\n",
        "      \"Your appointment for {date} has been booked.\",\n",
        "      \"Your appointment has been successfully scheduled for {date}.\",\n",
        "      \"We’ve booked your appointment for {date}.\"\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"intent\": \"service_scheduling\",\n",
        "    \"patterns\": [\n",
        "      \"Schedule a service for {date} at {time}\",\n",
        "      \"Set up a service appointment on {date} at {time}\",\n",
        "      \"I want to schedule a service on {date} at {time}\",\n",
        "      \"Can I set up a service for {date} at {time}?\",\n",
        "      \"Please schedule a service for me on {date} at {time}\",\n",
        "      \"Book a service for {date} at {time}\",\n",
        "      \"I need to schedule a service on {date} at {time}\",\n",
        "      \"Schedule maintenance on {date} at {time}\",\n",
        "      \"Can you schedule a service for {date} at {time}?\",\n",
        "      \"I’d like to book a service for {date} at {time}\"\n",
        "    ],\n",
        "    \"responses\": [\n",
        "      \"Your service appointment for {date} at {time} has been scheduled.\",\n",
        "      \"We’ve scheduled your service for {date} at {time}.\",\n",
        "      \"Your service has been booked for {date} at {time}.\"\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"intent\": \"pricing_query\",\n",
        "    \"patterns\": [\n",
        "      \"What is the price for {service}?\",\n",
        "      \"How much does {service} cost?\",\n",
        "      \"Tell me the pricing for {service}.\",\n",
        "      \"What’s the cost of {service}?\",\n",
        "      \"How much is {service}?\",\n",
        "      \"Can you give me the pricing for {service}?\",\n",
        "      \"I need the price for {service}.\",\n",
        "      \"What’s the rate for {service}?\",\n",
        "      \"Please provide the pricing details for {service}.\",\n",
        "      \"How much do you charge for {service}?\"\n",
        "    ],\n",
        "    \"responses\": [\n",
        "      \"The pricing for {service} starts at $50.\",\n",
        "      \"The cost of {service} is $50 and above.\",\n",
        "      \"The starting price for {service} is $50.\"\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"intent\": \"greeting\",\n",
        "    \"patterns\": [\n",
        "      \"Hi\",\n",
        "      \"Hello\",\n",
        "      \"Hey\",\n",
        "      \"Good morning\",\n",
        "      \"Good afternoon\",\n",
        "      \"Good evening\",\n",
        "      \"Greetings\",\n",
        "      \"How are you?\",\n",
        "      \"Is anyone there?\",\n",
        "      \"Hello, can you assist me?\"\n",
        "    ],\n",
        "    \"responses\": [\n",
        "      \"Hello! How can I help you today?\",\n",
        "      \"Hi there! What can I do for you?\",\n",
        "      \"Hey! How can I assist you today?\"\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"intent\": \"farewell\",\n",
        "    \"patterns\": [\n",
        "      \"Goodbye\",\n",
        "      \"Bye\",\n",
        "      \"See you later\",\n",
        "      \"Thanks, bye\",\n",
        "      \"Talk to you later\",\n",
        "      \"I’m done, goodbye\",\n",
        "      \"Catch you later\",\n",
        "      \"Take care\",\n",
        "      \"Bye for now\",\n",
        "      \"Have a good day\"\n",
        "    ],\n",
        "    \"responses\": [\n",
        "      \"Goodbye! Have a great day!\",\n",
        "      \"Bye! Let me know if you need anything else.\",\n",
        "      \"See you later! Take care.\"\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"intent\": \"service_availability\",\n",
        "    \"patterns\": [\n",
        "      \"Is {service} available on {date}?\",\n",
        "      \"Can I book {service} for {date}?\",\n",
        "      \"Do you offer {service}?\",\n",
        "      \"Are you available for {service} on {date}?\",\n",
        "      \"Can I schedule {service} on {date}?\",\n",
        "      \"Is there availability for {service} on {date}?\",\n",
        "      \"Can I get {service} on {date}?\",\n",
        "      \"I want to check availability for {service} on {date}.\",\n",
        "      \"Is {service} open on {date}?\",\n",
        "      \"Can I book {service}?\"\n",
        "    ],\n",
        "    \"responses\": [\n",
        "      \"{service} is available on {date}. Would you like to proceed with booking?\",\n",
        "      \"Yes, we can provide {service} on {date}. Shall we book it?\",\n",
        "      \"The {service} is available. Would you like to schedule it?\"\n",
        "    ]\n",
        "  }\n",
        "]\n",
        "\n",
        "# Save the JSON data to a file\n",
        "with open(\"chatbot_data.json\", \"w\") as file:\n",
        "    json.dump(chatbot_data, file, indent=4)\n",
        "\n",
        "print(\"JSON file created!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kQNqn6DtXvOU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcChpCT3j622",
        "outputId": "b0498839-d08a-43c0-ef47-541aeb6fef19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intent: appointment_booking\n",
            "Patterns: ['Book an appointment for {date}', 'Schedule an appointment on {date}', 'I want to book an appointment for {date}', 'Can I book an appointment for {date}?', 'Please schedule my appointment on {date}', 'Make an appointment for me on {date}', 'Reserve an appointment on {date}', 'I need an appointment for {date}', 'Set up an appointment for {date}', 'Schedule a meeting on {date}']\n",
            "Response: ['Your appointment for {date} has been booked.', 'Your appointment has been successfully scheduled for {date}.', 'We’ve booked your appointment for {date}.']\n",
            "----\n",
            "Intent: service_scheduling\n",
            "Patterns: ['Schedule a service for {date} at {time}', 'Set up a service appointment on {date} at {time}', 'I want to schedule a service on {date} at {time}', 'Can I set up a service for {date} at {time}?', 'Please schedule a service for me on {date} at {time}', 'Book a service for {date} at {time}', 'I need to schedule a service on {date} at {time}', 'Schedule maintenance on {date} at {time}', 'Can you schedule a service for {date} at {time}?', 'I’d like to book a service for {date} at {time}']\n",
            "Response: ['Your service appointment for {date} at {time} has been scheduled.', 'We’ve scheduled your service for {date} at {time}.', 'Your service has been booked for {date} at {time}.']\n",
            "----\n",
            "Intent: pricing_query\n",
            "Patterns: ['What is the price for {service}?', 'How much does {service} cost?', 'Tell me the pricing for {service}.', 'What’s the cost of {service}?', 'How much is {service}?', 'Can you give me the pricing for {service}?', 'I need the price for {service}.', 'What’s the rate for {service}?', 'Please provide the pricing details for {service}.', 'How much do you charge for {service}?']\n",
            "Response: ['The pricing for {service} starts at $50.', 'The cost of {service} is $50 and above.', 'The starting price for {service} is $50.']\n",
            "----\n",
            "Intent: greeting\n",
            "Patterns: ['Hi', 'Hello', 'Hey', 'Good morning', 'Good afternoon', 'Good evening', 'Greetings', 'How are you?', 'Is anyone there?', 'Hello, can you assist me?']\n",
            "Response: ['Hello! How can I help you today?', 'Hi there! What can I do for you?', 'Hey! How can I assist you today?']\n",
            "----\n",
            "Intent: farewell\n",
            "Patterns: ['Goodbye', 'Bye', 'See you later', 'Thanks, bye', 'Talk to you later', 'I’m done, goodbye', 'Catch you later', 'Take care', 'Bye for now', 'Have a good day']\n",
            "Response: ['Goodbye! Have a great day!', 'Bye! Let me know if you need anything else.', 'See you later! Take care.']\n",
            "----\n",
            "Intent: service_availability\n",
            "Patterns: ['Is {service} available on {date}?', 'Can I book {service} for {date}?', 'Do you offer {service}?', 'Are you available for {service} on {date}?', 'Can I schedule {service} on {date}?', 'Is there availability for {service} on {date}?', 'Can I get {service} on {date}?', 'I want to check availability for {service} on {date}.', 'Is {service} open on {date}?', 'Can I book {service}?']\n",
            "Response: ['{service} is available on {date}. Would you like to proceed with booking?', 'Yes, we can provide {service} on {date}. Shall we book it?', 'The {service} is available. Would you like to schedule it?']\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Load the JSON file\n",
        "with open(\"chatbot_data.json\", \"r\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# The data loaded is a list of intents. Directly iterate through it\n",
        "# instead of looking for an \"intents\" key:\n",
        "intents = data  # Assign the loaded data directly to intents\n",
        "\n",
        "# Check loaded data\n",
        "for intent in intents:\n",
        "    print(f\"Intent: {intent['intent']}\") # Access the intent name using 'intent' key\n",
        "    print(f\"Patterns: {intent['patterns']}\")\n",
        "    print(f\"Response: {intent['responses']}\") # Access the responses using 'responses' key\n",
        "    print(\"----\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDvAsJaGcs-p"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Extract patterns and labels\n",
        "patterns = []\n",
        "labels = []\n",
        "label_map = {intent[\"intent\"]: idx for idx, intent in enumerate(intents)}\n",
        "\n",
        "for intent in intents:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        patterns.append(pattern)\n",
        "        labels.append(label_map[intent[\"intent\"]])\n",
        "\n",
        "# Split data into training and testing\n",
        "train_patterns, test_patterns, train_labels, test_labels = train_test_split(\n",
        "    patterns, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Tokenize patterns using BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "train_encodings = tokenizer(train_patterns, truncation=True, padding=True, max_length=64, return_tensors=\"pt\")\n",
        "test_encodings = tokenizer(test_patterns, truncation=True, padding=True, max_length=64, return_tensors=\"pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50AU0Z6RdgLJ",
        "outputId": "2bcadf93-307a-4a7f-8b1e-6d2dc8ddfb51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertForSequenceClassification, AdamW\n",
        "\n",
        "class ChatDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "train_dataset = ChatDataset(train_encodings, train_labels)\n",
        "test_dataset = ChatDataset(test_encodings, test_labels)\n",
        "\n",
        "# Load BERT model for classification\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(label_map))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzWiRJkbd3SZ",
        "outputId": "1a0fae5d-624e-4eba-fd96-e0e36303b06b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 complete. Loss: 1.9106\n",
            "Epoch 2 complete. Loss: 1.5799\n",
            "Epoch 3 complete. Loss: 1.0634\n",
            "Epoch 4 complete. Loss: 0.8671\n",
            "Epoch 5 complete. Loss: 0.8340\n",
            "Epoch 6 complete. Loss: 0.6764\n",
            "Epoch 7 complete. Loss: 0.5428\n",
            "Epoch 8 complete. Loss: 0.3102\n",
            "Epoch 9 complete. Loss: 0.2471\n",
            "Epoch 10 complete. Loss: 0.1184\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fine_tuned_bert_model/tokenizer_config.json',\n",
              " 'fine_tuned_bert_model/special_tokens_map.json',\n",
              " 'fine_tuned_bert_model/vocab.txt',\n",
              " 'fine_tuned_bert_model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Training loop\n",
        "model.train()\n",
        "for epoch in range(10):  # 3 epochs\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} complete. Loss: {loss.item():.4f}\")\n",
        "# ... after the training loop in your code ...\n",
        "\n",
        "# Save the fine-tuned BERT model\n",
        "model.save_pretrained(\"fine_tuned_bert_model\")\n",
        "\n",
        "# Save the tokenizer as well (if you modified it)\n",
        "tokenizer.save_pretrained(\"fine_tuned_bert_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if6AETh3mSk6",
        "outputId": "df4af285-b051-4270-be63-f9cc5ec13184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Input: Book an appointment for {date}\n",
            "Predicted Intent: appointment_booking\n",
            "Response: ['Your appointment for {date} has been booked.', 'Your appointment has been successfully scheduled for {date}.', 'We’ve booked your appointment for {date}.']\n",
            "----\n",
            "User Input: Make an appointment for me on {date}\n",
            "Predicted Intent: appointment_booking\n",
            "Response: ['Your appointment for {date} has been booked.', 'Your appointment has been successfully scheduled for {date}.', 'We’ve booked your appointment for {date}.']\n",
            "----\n",
            "User Input: Greetings\n",
            "Predicted Intent: greeting\n",
            "Response: ['Hello! How can I help you today?', 'Hi there! What can I do for you?', 'Hey! How can I assist you today?']\n",
            "----\n",
            "User Input: I’m done, goodbye\n",
            "Predicted Intent: farewell\n",
            "Response: ['Goodbye! Have a great day!', 'Bye! Let me know if you need anything else.', 'See you later! Take care.']\n",
            "----\n",
            "User Input: Can I set up a service for {date} at {time}?\n",
            "Predicted Intent: service_scheduling\n",
            "Response: ['Your service appointment for {date} at {time} has been scheduled.', 'We’ve scheduled your service for {date} at {time}.', 'Your service has been booked for {date} at {time}.']\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "from torch.nn.functional import softmax\n",
        "\n",
        "model.eval()\n",
        "for test_pattern in test_patterns[:5]:  # Test with a few examples\n",
        "    inputs = tokenizer(test_pattern, truncation=True, padding=True, max_length=64, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    probs = softmax(outputs.logits, dim=-1)\n",
        "    predicted_label = torch.argmax(probs).item()\n",
        "    intent_name = list(label_map.keys())[list(label_map.values()).index(predicted_label)]\n",
        "\n",
        "    print(f\"User Input: {test_pattern}\")\n",
        "    print(f\"Predicted Intent: {intent_name}\")\n",
        "    # Change 'response' to 'responses' to match the key in your data\n",
        "    print(f\"Response: {next(intent['responses'] for intent in intents if intent['intent'] == intent_name)}\")\n",
        "    print(\"----\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlgVr7cRnSvy",
        "outputId": "fcf40f3e-3241-46d0-f5a1-ecb2d08b5649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Input: Book an appointment for 2024-12-25\n",
            "Predicted Intent: appointment_booking\n",
            "Response: ['Your appointment for {date} has been booked.', 'Your appointment has been successfully scheduled for {date}.', 'We’ve booked your appointment for {date}.']\n",
            "----\n",
            "User Input: Schedule a service for 2024-12-25 at 10:00 AM\n",
            "Predicted Intent: service_scheduling\n",
            "Response: ['Your service appointment for {date} at {time} has been scheduled.', 'We’ve scheduled your service for {date} at {time}.', 'Your service has been booked for {date} at {time}.']\n",
            "----\n",
            "User Input: What is the price for car repair?\n",
            "Predicted Intent: pricing_query\n",
            "Response: ['The pricing for {service} starts at $50.', 'The cost of {service} is $50 and above.', 'The starting price for {service} is $50.']\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "test_inputs = [\n",
        "    \"Book an appointment for 2024-12-25\",\n",
        "    \"Schedule a service for 2024-12-25 at 10:00 AM\",\n",
        "    \"What is the price for car repair?\"\n",
        "]\n",
        "\n",
        "for input_text in test_inputs:\n",
        "    inputs = tokenizer(input_text, truncation=True, padding=True, max_length=64, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    probs = softmax(outputs.logits, dim=-1)\n",
        "    predicted_label = torch.argmax(probs).item()\n",
        "    intent_name = list(label_map.keys())[list(label_map.values()).index(predicted_label)]\n",
        "    print(f\"User Input: {input_text}\")\n",
        "    print(f\"Predicted Intent: {intent_name}\")\n",
        "    # Corrected line: Access the 'responses' key instead of 'response'\n",
        "    print(f\"Response: {next(intent['responses'] for intent in intents if intent['intent'] == intent_name)}\")\n",
        "    print(\"----\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn7CfO__o_E7",
        "outputId": "ff8e7e0d-f411-4ecb-e14d-efdd4777ae31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Input: {'intent': 'appointment_booking', 'entities': {'date': '2024-12-25'}}\n",
            "Predicted Intent: appointment_booking\n",
            "Response: Your appointment for 2024-12-25 has been booked.\n",
            "----\n",
            "User Input: {'intent': 'service_scheduling', 'entities': {'date': '2024-12-25', 'time': '10:00 AM'}}\n",
            "Predicted Intent: service_scheduling\n",
            "Response: Your service appointment for 2024-12-25 at 10:00 AM has been scheduled.\n",
            "----\n",
            "User Input: {'intent': 'pricing_query', 'entities': {'service': 'car repair'}}\n",
            "Predicted Intent: pricing_query\n",
            "Response: The starting price for car repair is $50.\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# Define a function to generate dynamic responses\n",
        "def generate_response(intent, entities):\n",
        "    response_data = {\n",
        "        \"appointment_booking\": [\n",
        "            \"Your appointment for {date} has been booked.\",\n",
        "            \"Your appointment has been successfully scheduled for {date}.\",\n",
        "            \"We’ve booked your appointment for {date}.\"\n",
        "        ],\n",
        "        \"service_scheduling\": [\n",
        "            \"Your service appointment for {date} at {time} has been scheduled.\",\n",
        "            \"We’ve scheduled your service for {date} at {time}.\",\n",
        "            \"Your service has been booked for {date} at {time}.\"\n",
        "        ],\n",
        "        \"pricing_query\": [\n",
        "            \"The pricing for {service} starts at $50.\",\n",
        "            \"The cost of {service} is $50 and above.\",\n",
        "            \"The starting price for {service} is $50.\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Get the list of responses for the intent\n",
        "    responses = response_data.get(intent, [\"I'm sorry, I didn't understand that.\"])\n",
        "\n",
        "    # Randomly select a response\n",
        "    response_template = random.choice(responses)\n",
        "\n",
        "    # Substitute placeholders with actual entity values\n",
        "    response = response_template.format(**entities)\n",
        "    return response\n",
        "\n",
        "# Example Inputs\n",
        "inputs = [\n",
        "    {\"intent\": \"appointment_booking\", \"entities\": {\"date\": \"2024-12-25\"}},\n",
        "    {\"intent\": \"service_scheduling\", \"entities\": {\"date\": \"2024-12-25\", \"time\": \"10:00 AM\"}},\n",
        "    {\"intent\": \"pricing_query\", \"entities\": {\"service\": \"car repair\"}}\n",
        "]\n",
        "\n",
        "# Generate and print responses\n",
        "for user_input in inputs:\n",
        "    intent = user_input[\"intent\"]\n",
        "    entities = user_input[\"entities\"]\n",
        "    print(f\"User Input: {user_input}\")\n",
        "    print(f\"Predicted Intent: {intent}\")\n",
        "    print(f\"Response: {generate_response(intent, entities)}\")\n",
        "    print(\"----\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0DQu1AwLBRm",
        "outputId": "19d4208c-0f26-44d2-9853-61aedd7317ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Entities: {'DATE': 'December 25', 'TIME': '10:00 AM'}\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# Load the pre-trained spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to extract entities\n",
        "def extract_entities(user_input):\n",
        "    doc = nlp(user_input)\n",
        "    entities = {}\n",
        "    for ent in doc.ents:\n",
        "        entities[ent.label_] = ent.text\n",
        "    return entities\n",
        "\n",
        "# Example usage\n",
        "user_input = \"Book an appointment for December 25 at 10:00 AM.\"\n",
        "extracted_entities = extract_entities(user_input)\n",
        "print(\"Extracted Entities:\", extracted_entities)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQLvpoPlONZh",
        "outputId": "64c10e40-689c-402e-bd32-7f2f78b0d2ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot Response: Your appointment has been booked for December 25 at 10:00 AM.\n"
          ]
        }
      ],
      "source": [
        "# Example: Integrating NER in a chatbot\n",
        "def chatbot_response(user_input):\n",
        "    # Extract entities\n",
        "    entities = extract_entities(user_input)\n",
        "\n",
        "    # Example intents and responses\n",
        "    if \"DATE\" in entities and \"TIME\" in entities:\n",
        "        return f\"Your appointment has been booked for {entities['DATE']} at {entities['TIME']}.\"\n",
        "    elif \"DATE\" in entities:\n",
        "        return f\"What time would you like to schedule your appointment on {entities['DATE']}?\"\n",
        "    else:\n",
        "        return \"I’m sorry, I didn’t understand. Could you provide more details?\"\n",
        "\n",
        "# Example usage\n",
        "user_input = \"Book an appointment for December 25 at 10:00 AM.\"\n",
        "response = chatbot_response(user_input)\n",
        "print(\"Chatbot Response:\", response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWnG0BVJPDw3"
      },
      "outputs": [],
      "source": [
        "TRAIN_DATA = [\n",
        "    (\"Book an appointment for December 25 at 10:00 AM.\", {\n",
        "        \"entities\": [(23, 35, \"DATE\"), (39, 47, \"TIME\")]\n",
        "    }),\n",
        "    (\"Schedule a service for January 10.\", {\n",
        "        \"entities\": [(24, 33, \"DATE\")]\n",
        "    }),\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6GjzroJQSHd",
        "outputId": "9f280b06-0840-4d4e-8b42-aa48811b842c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BILUO Tags: ['O', 'O', 'O', 'O', '-', '-', 'O', 'B-TIME', 'L-TIME', 'O']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Book an appointment for December 25 at 10:00 AM.\" with entities \"[(23, 35, 'DATE'), (39, 47, 'TIME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from spacy.training import offsets_to_biluo_tags\n",
        "\n",
        "# Example of misaligned text and entities\n",
        "text = \"Book an appointment for December 25 at 10:00 AM.\"\n",
        "entities = [(23, 35, \"DATE\"), (39, 47, \"TIME\")]\n",
        "\n",
        "# Check alignment\n",
        "doc = nlp.make_doc(text)\n",
        "biluo_tags = offsets_to_biluo_tags(doc, entities)\n",
        "print(\"BILUO Tags:\", biluo_tags)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKgL3EKyQZH2"
      },
      "outputs": [],
      "source": [
        "def adjust_offsets(text, entities):\n",
        "    adjusted_entities = []\n",
        "    for start, end, label in entities:\n",
        "        entity_text = text[start:end]\n",
        "        # Verify if the extracted text matches the expected substring\n",
        "        if entity_text == text[start:end]:\n",
        "            adjusted_entities.append((start, end, label))\n",
        "        else:\n",
        "            print(f\"Misaligned entity: {entity_text}, Expected: {text[start:end]}\")\n",
        "    return adjusted_entities\n",
        "\n",
        "# Correct the training data\n",
        "TRAIN_DATA = [\n",
        "    (\"Book an appointment for December 25 at 10:00 AM.\", {\n",
        "        \"entities\": adjust_offsets(\"Book an appointment for December 25 at 10:00 AM.\", [\n",
        "            (23, 35, \"DATE\"), (39, 47, \"TIME\")\n",
        "        ])\n",
        "    }),\n",
        "    (\"Schedule a service for January 10.\", {\n",
        "        \"entities\": adjust_offsets(\"Schedule a service for January 10.\", [\n",
        "            (24, 33, \"DATE\")\n",
        "        ])\n",
        "    }),\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwYFyS0dE5MB",
        "outputId": "0f433f54-7ac7-4a45-92ef-4a7a9ffda6e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Schedule a service for January 10.\" with entities \"[(24, 33, 'DATE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ner': 11.959658339619637}\n",
            "{'ner': 11.008101508021355}\n",
            "{'ner': 10.071110516786575}\n",
            "{'ner': 8.555093865841627}\n",
            "{'ner': 7.353826265782118}\n",
            "{'ner': 6.212025132030249}\n",
            "{'ner': 4.584280813112855}\n",
            "{'ner': 3.26092179864645}\n",
            "{'ner': 2.3964913389645517}\n",
            "{'ner': 2.0006963657215238}\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy.training import Example\n",
        "from spacy.pipeline.ner import DEFAULT_NER_MODEL\n",
        "\n",
        "# Your existing training data (TRAIN_DATA)\n",
        "\n",
        "# 1. Create a blank English language model\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "# 2. Add the NER component\n",
        "ner = nlp.add_pipe(\"ner\", config={\"model\": DEFAULT_NER_MODEL})\n",
        "\n",
        "# 3. Add labels to the NER component\n",
        "for _, annotations in TRAIN_DATA:\n",
        "    for ent in annotations.get(\"entities\"):\n",
        "        ner.add_label(ent[2])\n",
        "\n",
        "# 4. Disable other pipeline components during training\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
        "with nlp.disable_pipes(*other_pipes):\n",
        "    # Train the model\n",
        "    optimizer = nlp.begin_training()\n",
        "    for itn in range(10):  # Adjust the number of iterations as needed\n",
        "        random.shuffle(TRAIN_DATA)\n",
        "        losses = {}\n",
        "        for text, annotations in TRAIN_DATA:\n",
        "            example = Example.from_dict(nlp.make_doc(text), annotations)\n",
        "            nlp.update([example], drop=0.5, sgd=optimizer, losses=losses)\n",
        "        print(losses)\n",
        "\n",
        "# 5. Save the trained model\n",
        "nlp.to_disk(\"custom_ner_model\")\n",
        "\n",
        "# Now you can load the saved model:\n",
        "nlp = spacy.load(\"custom_ner_model\")\n",
        "\n",
        "# Test the model (your existing test code)\n",
        "user_input = \"Book an appointment for December 25 at 10:00 AM.\"\n",
        "doc = nlp(user_input)\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "li7HLRKLQm0F"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"custom_ner_model\")\n",
        "\n",
        "# Test the model\n",
        "user_input = \"Book an appointment for December 25 at 10:00 AM.\"\n",
        "doc = nlp(user_input)\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sWLTK3MS7Ch",
        "outputId": "fa37aadf-3490-4bbb-9136-6cf1a7e32f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: twilio in /usr/local/lib/python3.10/dist-packages (9.4.1)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from twilio) (2.32.3)\n",
            "Requirement already satisfied: PyJWT<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from twilio) (2.10.1)\n",
            "Requirement already satisfied: aiohttp>=3.8.4 in /usr/local/lib/python3.10/dist-packages (from twilio) (3.11.10)\n",
            "Requirement already satisfied: aiohttp-retry==2.8.3 in /usr/local/lib/python3.10/dist-packages (from twilio) (2.8.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->twilio) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->twilio) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->twilio) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->twilio) (2024.12.14)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp>=3.8.4->twilio) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "pip install twilio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV38zS7Ce6fR",
        "outputId": "d858f2a2-4497-4257-f3f6-f22ec8ff91a8"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ],
      "source": [
        "from twilio.rest import Client\n",
        "from flask import Flask, request, jsonify\n",
        "import spacy\n",
        "\n",
        "# Load your trained NER model\n",
        "nlp = spacy.load(\"custom_ner_model\")\n",
        "\n",
        "# Twilio credentials (replace with your credentials)\n",
        "TWILIO_ACCOUNT_SID = \"ACe9b71170050da74ebb07b67a02513e54\"\n",
        "TWILIO_AUTH_TOKEN = \"62c27b9b3337c6ac377c42ac02ce5cb4\"\n",
        "TWILIO_PHONE_NUMBER = \"+12185495883\"\n",
        "\n",
        "# Initialize Twilio client\n",
        "client = Client(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN)\n",
        "\n",
        "# Flask app for handling incoming messages\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Chatbot response logic\n",
        "def chatbot_response(user_input):\n",
        "    doc = nlp(user_input)\n",
        "    entities = {ent.label_: ent.text for ent in doc.ents}\n",
        "\n",
        "    # Example logic for responding to intents\n",
        "    if \"DATE\" in entities:\n",
        "        return f\"Your appointment for {entities['DATE']} has been scheduled.\"\n",
        "    elif \"TIME\" in entities:\n",
        "        return f\"The selected time is {entities['TIME']}. Please confirm.\"\n",
        "    else:\n",
        "        return \"I'm sorry, I didn't understand that. Could you rephrase?\"\n",
        "\n",
        "# Endpoint to receive messages from Twilio\n",
        "@app.route(\"/twilio-webhook\", methods=[\"POST\"])\n",
        "def twilio_webhook():\n",
        "    incoming_message = request.form.get(\"Body\")\n",
        "    user_number = request.form.get(\"From\")\n",
        "\n",
        "    # Generate chatbot response\n",
        "    response_message = chatbot_response(incoming_message)\n",
        "\n",
        "    # Send response back to the user via Twilio\n",
        "    client.messages.create(\n",
        "        body=response_message,\n",
        "        from_=TWILIO_PHONE_NUMBER,\n",
        "        to=user_number\n",
        "    )\n",
        "\n",
        "    return jsonify({\"status\": \"Message Sent\", \"response\": response_message})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(host=\"0.0.0.0\", port=5000, debug=True)\n"
      ]
    },
    {
      "source": [
        "from twilio.rest import Client\n",
        "import os\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.nn.functional import softmax\n",
        "import re\n",
        "# Twilio credentials (from Twilio Console)\n",
        "os.environ['TWILIO_ACCOUNT_SID'] = 'ACe9b71170050da74ebb07b67a02513e54'\n",
        "os.environ['TWILIO_AUTH_TOKEN'] = '62c27b9b3337c6ac377c42ac02ce5cb4'\n",
        "\n",
        "# Load your trained model\n",
        "model_path = \"custom_ner_model\" # or your model's path\n",
        "nlp = spacy.load(model_path)\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "model_path = \"fine_tuned_bert_model\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=len(label_map))  # Assuming you have label_map defined\n",
        "\n",
        "# Define a function to extract entities\n",
        "def extract_entities(user_input):\n",
        "    doc = nlp(user_input)\n",
        "    entities = {}\n",
        "    for ent in doc.ents:\n",
        "        entities[ent.label_] = ent.text\n",
        "    return entities\n",
        "\n",
        "# Updated get_model_response function with your actual model logic\n",
        "def get_model_response(user_input):\n",
        "    # 1. Extract entities\n",
        "    entities = extract_entities(user_input)\n",
        "    # 2. Tokenize and get model predictions\n",
        "    inputs = tokenizer(user_input, truncation=True, padding=True, max_length=64, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    probs = softmax(outputs.logits, dim=-1)\n",
        "    predicted_label = torch.argmax(probs).item()\n",
        "    intent_name = list(label_map.keys())[list(label_map.values()).index(predicted_label)]\n",
        "    # 3. Generate response\n",
        "    return generate_response(intent_name, entities) # Assuming you have generate_response function defined\n",
        "\n",
        "\n",
        "# Define a function to generate dynamic responses\n",
        "def generate_response(intent, entities):\n",
        "    response_data = {\n",
        "        \"appointment_booking\": [\n",
        "            \"Your appointment for {date} has been booked.\",\n",
        "            \"Your appointment has been successfully scheduled for {date}.\",\n",
        "            \"We’ve booked your appointment for {date}.\"\n",
        "        ],\n",
        "        \"service_scheduling\": [\n",
        "            \"Your service appointment for {date} at {time} has been scheduled.\",\n",
        "            \"We’ve scheduled your service for {date} at {time}.\",\n",
        "            \"Your service has been booked for {date} at {time}.\"\n",
        "        ],\n",
        "        \"pricing_query\": [\n",
        "            \"The pricing for {service} starts at $50.\",\n",
        "            \"The cost of {service} is $50 and above.\",\n",
        "            \"The starting price for {service} is $50.\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Get the list of responses for the intent\n",
        "    responses = response_data.get(intent, [\"I'm sorry, I didn't understand that.\"])\n",
        "\n",
        "    # Randomly select a response\n",
        "    import random\n",
        "    response_template = random.choice(responses)\n",
        "    if 'date' not in entities:\n",
        "        date_match = re.search(r'\\d{1,2}/\\d{1,2}/\\d{4}', user_input)\n",
        "        if date_match:\n",
        "            entities['date'] = date_match.group(0)\n",
        "    # Substitute placeholders with actual entity values\n",
        "    response = response_template.format(**entities)\n",
        "    return response\n",
        "\n",
        "# Simulate user input\n",
        "user_input = \"Book an appointment for 26/12/2024\"\n",
        "\n",
        "# Generate a response using your model\n",
        "model_response = get_model_response(user_input)\n",
        "\n",
        "# Initialize the Twilio Client\n",
        "client = Client(os.environ['TWILIO_ACCOUNT_SID'], os.environ['TWILIO_AUTH_TOKEN'])\n",
        "\n",
        "# Sending SMS with model's response\n",
        "message = client.messages.create(\n",
        "    body=f\"Model Response: {model_response}\",  # Message body from model\n",
        "    from_='+12185495883',  # Twilio phone number (your Twilio number)\n",
        "    to='+918688272541'     # Recipient's phone number\n",
        ")\n",
        "\n",
        "# Print message SID (optional, useful for debugging)\n",
        "print(f\"Message sent! SID: {message.sid}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "6TSa-z3uK204",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82d20e79-a1a9-4646-81a1-2637882be1a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message sent! SID: SM19c9ebfff21f525002bdf06294301423\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}